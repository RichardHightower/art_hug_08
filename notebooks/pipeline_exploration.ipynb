{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline Exploration Notebook\n",
    "\n",
    "This notebook provides interactive examples for exploring Hugging Face pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from transformers import pipeline, logging\n",
    "import torch\n",
    "from src.config import get_device, DEFAULT_SENTIMENT_MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Pipeline Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple pipeline\n",
    "device = get_device()\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "clf = pipeline(\n",
    "    'sentiment-analysis',\n",
    "    model=DEFAULT_SENTIMENT_MODEL,\n",
    "    device=0 if device == 'cuda' else -1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the pipeline\n",
    "texts = [\n",
    "    \"I love this product!\",\n",
    "    \"This is terrible.\",\n",
    "    \"It's okay, not great.\"\n",
    "]\n",
    "\n",
    "results = clf(texts)\n",
    "for text, result in zip(texts, results):\n",
    "    print(f\"{text}: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pipeline Internals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect pipeline components\n",
    "print(\"Model architecture:\")\n",
    "print(clf.model)\n",
    "\n",
    "print(\"\\nTokenizer info:\")\n",
    "print(f\"Vocab size: {clf.tokenizer.vocab_size}\")\n",
    "print(f\"Max length: {clf.tokenizer.model_max_length}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Custom Pipeline Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.custom_pipelines import CustomSentimentPipeline\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "# Create custom pipeline\n",
    "model = AutoModelForSequenceClassification.from_pretrained(DEFAULT_SENTIMENT_MODEL)\n",
    "tokenizer = AutoTokenizer.from_pretrained(DEFAULT_SENTIMENT_MODEL)\n",
    "\n",
    "custom_pipe = CustomSentimentPipeline(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    device=0 if device == 'cuda' else -1\n",
    ")\n",
    "\n",
    "# Test with messy input\n",
    "messy_texts = [\n",
    "    \"<p>AMAZING PRODUCT!!!</p>\",\n",
    "    \"terrible... just terrible!!!!!!\",\n",
    "    \"   Good value   \"\n",
    "]\n",
    "\n",
    "custom_results = custom_pipe(messy_texts)\n",
    "for text, result in zip(messy_texts, custom_results):\n",
    "    print(f\"\\nInput: {text}\")\n",
    "    print(f\"Result: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Generate test data\n",
    "test_texts = [\"This is a test sentence.\"] * 100\n",
    "\n",
    "# Test different batch sizes\n",
    "batch_sizes = [1, 8, 16, 32]\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    start = time.time()\n",
    "    _ = clf(test_texts, batch_size=batch_size)\n",
    "    end = time.time()\n",
    "    \n",
    "    throughput = len(test_texts) / (end - start)\n",
    "    print(f\"Batch size {batch_size}: {throughput:.1f} samples/sec\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
